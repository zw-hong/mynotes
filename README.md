# NMT Paper Reading

Start from 2022.6.13 üôÄ

## Must reads

- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)
- [Neural Machine Translation of Rare Words with Subword Units(BPE)](https://arxiv.org/abs/1508.07909)
- [BLEU: a Method for Automatic Evaluation of Machine Translation](https://aclanthology.org/P02-1040.pdf)
- [Moses: Open Source Toolkit for Statistical Machine Translation](https://aclanthology.org/P07-2045/)



## Neural Machine Translation 



#### Attention Mechanism 

- [Attention Calibration for Transformer in Neural Machine Translation](https://aclanthology.org/2021.acl-long.103.pdf)

#### Pre-training 

- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)

#### Quality Estimation 

- [TransQuest at WMT2020: Sentence-Level Direct Assessment](https://arxiv.org/abs/2011.01536)
- [TransQuest: Translation Quality Estimation with Cross-lingual Transformers](https://arxiv.org/abs/2010.05318)



## Others

- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385?context=cs)







## My reading timeline 

##### ‚è∞2022.6.20

- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

##### ‚è∞2022.6.27

- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385?context=cs)

##### ‚è∞2022.7.4

[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)

##### ‚è∞2022.7.11

- [Attention Calibration for Transformer in Neural Machine Translation](https://aclanthology.org/2021.acl-long.103.pdf)

ÔºàÂï•‰πü‰∏ç‰ºöÂ±ÖÁÑ∂ÁªÑ‰ºöÊ±áÊä•Ôºâ

##### ‚è∞2022.7.18

- [Neural Machine Translation of Rare Words with Subword Units(BPE)](https://arxiv.org/abs/1508.07909)
- [BLEU: a Method for Automatic Evaluation of Machine Translation](https://aclanthology.org/P02-1040.pdf)
- [Moses: Open Source Toolkit for Statistical Machine Translation](https://aclanthology.org/P07-2045/)

##### ‚è∞2022.7.25

- [TransQuest at WMT2020: Sentence-Level Direct Assessment](https://arxiv.org/abs/2011.01536)
- [TransQuest: Translation Quality Estimation with Cross-lingual Transformers](https://arxiv.org/abs/2010.05318)
- [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)



